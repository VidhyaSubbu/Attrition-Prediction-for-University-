{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas_profiling as pd_prf\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\IPBAM065\\\\Documents'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_data=pd.read_excel('Bridge i2i.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3400, 56)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputing missing values in stdnt_test_entrance_comb column based on mean of stdnt_major\n",
    "\n",
    "std_data['STDNT_TEST_ENTRANCE_COMB'] = std_data['STDNT_TEST_ENTRANCE_COMB'].fillna(std_data.groupby('STDNT_MAJOR')['STDNT_TEST_ENTRANCE_COMB'].transform('mean'))\n",
    "\n",
    "# To identify absentees \n",
    "\n",
    "std_data['absentee_hrs_f'] = std_data['FIRST_TERM_ATTEMPT_HRS'] - std_data['FIRST_TERM_EARNED_HRS'] # For 1st semester absence\n",
    "std_data['absentee_hrs_s'] = std_data['SECOND_TERM_ATTEMPT_HRS'] - std_data['SECOND_TERM_EARNED_HRS'] # For 2nd semester absence\n",
    "\n",
    "# Parents eduction level - considering based on highest of parents education\n",
    "\n",
    "std_data['prnts_edn_cd'] = std_data[['FATHER_HI_EDU_CD','MOTHER_HI_EDU_CD']].max(axis=1)\n",
    "\n",
    "# Values mapping for students grade\n",
    "\n",
    "std_data['grade_1_f'] = std_data.CORE_COURSE_GRADE_1_F.map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'INCOMP':-1,'NOT REP':-1})\n",
    "std_data['grade_2_f'] = std_data.CORE_COURSE_GRADE_2_F.map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'INCOMP':-1,'NOT REP':-1})\n",
    "std_data['grade_3_f'] = std_data.CORE_COURSE_GRADE_3_F.map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'INCOMP':-1,'NOT REP':-1})\n",
    "std_data['grade_4_f'] = std_data.CORE_COURSE_GRADE_4_F.map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'INCOMP':-1,'NOT REP':-1})\n",
    "std_data['grade_5_f'] = std_data.CORE_COURSE_GRADE_5_F.map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'INCOMP':-1,'NOT REP':-1})\n",
    "std_data['grade_6_f'] = std_data.CORE_COURSE_GRADE_6_F.map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'INCOMP':-1,'NOT REP':-1})\n",
    "\n",
    "std_data['grade_1_s'] = std_data.CORE_COURSE_GRADE_1_S.map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'INCOMP':-1,'NOT REP':-1})\n",
    "std_data['grade_2_s'] = std_data.CORE_COURSE_GRADE_2_S.map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'INCOMP':-1,'NOT REP':-1})\n",
    "std_data['grade_3_s'] = std_data.CORE_COURSE_GRADE_3_S.map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'INCOMP':-1,'NOT REP':-1})\n",
    "std_data['grade_4_s'] = std_data.CORE_COURSE_GRADE_4_S.map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'INCOMP':-1,'NOT REP':-1})\n",
    "std_data['grade_5_s'] = std_data.CORE_COURSE_GRADE_5_S.map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'INCOMP':-1,'NOT REP':-1})\n",
    "std_data['grade_6_s'] = std_data.CORE_COURSE_GRADE_6_S.map({'A':1,'B':2,'C':3,'D':4,'E':5,'F':6,'INCOMP':-1,'NOT REP':-1})\n",
    "\n",
    "# Calculating grades average\n",
    "\n",
    "grds_cols = ['grade_1_f','grade_2_f','grade_3_f','grade_4_f','grade_5_f','grade_6_f','grade_1_s','grade_2_s','grade_3_s','grade_4_s','grade_5_s','grade_6_s']\n",
    "std_data['grd_avg'] = std_data[grds_cols].sum(axis=1)/std_data[grds_cols].count(axis=1)\n",
    "\n",
    "# Grade band\n",
    "\n",
    "std_data.loc[(std_data['grd_avg'] > 0) & (std_data['grd_avg'] <= 3) ,'grd_grp'] = 'Good'\n",
    "std_data.loc[(std_data['grd_avg'] > 3) & (std_data['grd_avg'] <= 5) ,'grd_grp'] = 'Average'\n",
    "std_data.loc[(std_data['grd_avg'] <= 0) | (std_data['grd_avg'] > 5) ,'grd_grp'] = 'Poor'\n",
    "\n",
    "# Students secured marks >= 1340 in STDNT_TEST_ENTRANCE_COMB\n",
    "\n",
    "std_data.loc[std_data['STDNT_TEST_ENTRANCE_COMB'] >= 1340,'entrance_score_ge1340'] = 1\n",
    "std_data.loc[std_data['STDNT_TEST_ENTRANCE_COMB'] < 1340,'entrance_score_ge1340'] = 0\n",
    "\n",
    "# Financial assistance required or not\n",
    "\n",
    "std_data.loc[std_data['UNMET_NEED'] > 0,'fin_asst_req'] = 1\n",
    "std_data.loc[std_data['UNMET_NEED'] <= 0,'fin_asst_req'] = 0\n",
    "\n",
    "# International status flag\n",
    "\n",
    "std_data.loc[std_data['INTERNATIONAL_STS'] == 'Y','intl_flag'] = 1\n",
    "std_data.loc[std_data['INTERNATIONAL_STS'] == 'N','intl_flag'] = 0\n",
    "\n",
    "# To identify which course students are leaving more - By removing numbers\n",
    "\n",
    "std_data['course1'] = std_data.CORE_COURSE_NAME_1_F.str[0:4]\n",
    "std_data['course2'] = std_data.CORE_COURSE_NAME_1_S.str[0:4]\n",
    "\n",
    "\n",
    "std_data.loc[std_data['course1'].isin(['ENGL','HIST','CHEM','MATH','ECON']),'top5_subj'] = 1\n",
    "std_data.loc[~std_data['course1'].isin(['ENGL','HIST','CHEM','MATH','ECON']),'top5_subj'] = 0\n",
    "\n",
    "std_data.loc[std_data['course2'].isin(['ENGL','HIST','CHEM','MATH','COMM']),'top5_subj'] = 1\n",
    "std_data.loc[~std_data['course2'].isin(['ENGL','HIST','CHEM','MATH','COMM']),'top5_subj'] = 0\n",
    "\n",
    "# Returned 2nd year flag update\n",
    "\n",
    "\n",
    "std_data['ret_2nd_yr'] = std_data.RETURNED_2ND_YR.map({0:1,1:0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age_eq18    2860\n",
       "age_eq17     309\n",
       "age_eq19     190\n",
       "age_ge20      33\n",
       "age_le16       8\n",
       "Name: age_grp, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Age cross tab\n",
    "\n",
    "age_crosstab = pd.crosstab(std_data['STDNT_AGE'],std_data['RETURNED_2ND_YR'])/std_data.shape[0]*100\n",
    "age_index = age_crosstab.reset_index()\n",
    "age_index['col']=age_index[0]/(age_index[0] + age_index[1])*100\n",
    "age_index\n",
    "\n",
    "# Age band creation\n",
    "\n",
    "std_data.loc[std_data['STDNT_AGE'] <= 16,'age_grp'] = 'age_le16'\n",
    "std_data.loc[std_data['STDNT_AGE'] == 17,'age_grp'] = 'age_eq17'\n",
    "std_data.loc[std_data['STDNT_AGE'] == 18,'age_grp'] = 'age_eq18'\n",
    "std_data.loc[std_data['STDNT_AGE'] == 19,'age_grp'] = 'age_eq19'\n",
    "std_data.loc[std_data['STDNT_AGE'] >= 20,'age_grp'] = 'age_ge20'\n",
    "\n",
    "std_data.age_grp.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender cross tab\n",
    "\n",
    "gend_crosstab = pd.crosstab(std_data['STDNT_GENDER'],std_data['RETURNED_2ND_YR'])/std_data.shape[0]*100\n",
    "gend_index = gend_crosstab.reset_index()\n",
    "gend_index['col']=gend_index[0]/(gend_index[0] + gend_index[1])*100\n",
    "gend_index\n",
    "\n",
    "# Gender Flag\n",
    "\n",
    "std_data.loc[std_data['STDNT_GENDER'] == 'M','gend_flag'] = 1\n",
    "std_data.loc[std_data['STDNT_GENDER'] == 'F','gend_flag'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BKGRND_1    2082\n",
       "OTHERS      1185\n",
       "BKGRND_2     106\n",
       "BKGRND_7      19\n",
       "BKGRND_5       8\n",
       "Name: std_bkgrnd_grp, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Student Background cross tab\n",
    "\n",
    "bkgrnd_crosstab = pd.crosstab(std_data['STDNT_BACKGROUND'],std_data['RETURNED_2ND_YR'])/std_data.shape[0]*100\n",
    "bkgrnd_index = bkgrnd_crosstab.reset_index()\n",
    "bkgrnd_index['col']=bkgrnd_index[0]/(bkgrnd_index[0] + bkgrnd_index[1])*100\n",
    "bkgrnd_index\n",
    "\n",
    "std_data.loc[std_data['STDNT_BACKGROUND'] == 'BGD 1','std_bkgrnd_grp'] = 'BKGRND_1'\n",
    "std_data.loc[std_data['STDNT_BACKGROUND'] == 'BGD 2','std_bkgrnd_grp'] = 'BKGRND_2'\n",
    "std_data.loc[std_data['STDNT_BACKGROUND'] == 'BGD 5','std_bkgrnd_grp'] = 'BKGRND_5'\n",
    "std_data.loc[std_data['STDNT_BACKGROUND'] == 'BGD 7','std_bkgrnd_grp'] = 'BKGRND_7'\n",
    "std_data.loc[std_data['STDNT_BACKGROUND'].isin(['BGD 3','BGD 4','BGD 6','BGD 8']),'std_bkgrnd_grp'] = 'OTHERS'\n",
    "\n",
    "std_data.std_bkgrnd_grp.value_counts()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    3384\n",
       "A      12\n",
       "V       4\n",
       "Name: DEGREE_GROUP_CD, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_data.DEGREE_GROUP_CD.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummies creation for 3 categorical variables\n",
    "incl_dummies = pd.get_dummies(data=std_data, columns=['grd_grp','age_grp','std_bkgrnd_grp'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [ 'STDNT_AGE','STDNT_GENDER', 'STDNT_BACKGROUND', 'INTERNATIONAL_STS', 'STDNT_MAJOR', 'STDNT_MINOR',\n",
    "            'STDNT_TEST_ENTRANCE1', 'STDNT_TEST_ENTRANCE2','STDNT_TEST_ENTRANCE1', 'STDNT_TEST_ENTRANCE2',\n",
    "            'FIRST_TERM', 'CORE_COURSE_NAME_1_F',\n",
    "           'CORE_COURSE_GRADE_1_F', 'CORE_COURSE_NAME_2_F', 'CORE_COURSE_GRADE_2_F', 'CORE_COURSE_NAME_3_F',\n",
    "           'CORE_COURSE_GRADE_3_F', 'CORE_COURSE_NAME_4_F', 'CORE_COURSE_GRADE_4_F', 'CORE_COURSE_NAME_5_F',\n",
    "           'CORE_COURSE_GRADE_5_F', 'CORE_COURSE_NAME_6_F', 'CORE_COURSE_GRADE_6_F', 'SECOND_TERM', 'CORE_COURSE_NAME_1_S',\n",
    "           'CORE_COURSE_GRADE_1_S', 'CORE_COURSE_NAME_2_S', 'CORE_COURSE_GRADE_2_S', 'CORE_COURSE_NAME_3_S',\n",
    "           'CORE_COURSE_GRADE_3_S', 'CORE_COURSE_NAME_4_S', 'CORE_COURSE_GRADE_4_S', 'CORE_COURSE_NAME_5_S',\n",
    "           'CORE_COURSE_GRADE_5_S', 'CORE_COURSE_NAME_6_S', 'CORE_COURSE_GRADE_6_S', 'HOUSING_STS', 'RETURNED_2ND_YR',\n",
    "           'HIGH_SCHL_NAME', 'FATHER_HI_EDU_CD', 'FATHER_HI_EDU_DESC', 'MOTHER_HI_EDU_CD',\n",
    "           'MOTHER_HI_EDU_DESC', 'DEGREE_GROUP_DESC', 'GROSS_FIN_NEED', 'UNMET_NEED',\n",
    "            'grade_1_f', 'grade_2_f', 'grade_3_f', 'grade_4_f', 'grade_5_f', 'grade_6_f', 'grade_1_s', 'grade_2_s', 'grade_3_s',\n",
    "       'grade_4_s', 'grade_5_s', 'grade_6_s', 'grd_avg','course1','course2','STUDENT IDENTIFIER',\n",
    "             'grd_grp_Average','std_bkgrnd_grp_OTHERS', 'DEGREE_GROUP_CD', 'IN_STATE_FLAG',\n",
    "             'std_bkgrnd_grp_BKGRND_1','std_bkgrnd_grp_BKGRND_2','std_bkgrnd_grp_BKGRND_5','std_bkgrnd_grp_BKGRND_7',\n",
    "             'age_grp_age_eq17','age_grp_age_eq18','age_grp_age_eq19','age_grp_age_le16'\n",
    "             \n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STDNT_TEST_ENTRANCE_COMB      0\n",
       "DISTANCE_FROM_HOME           25\n",
       "HIGH_SCHL_GPA                53\n",
       "FIRST_TERM_ATTEMPT_HRS        0\n",
       "FIRST_TERM_EARNED_HRS         0\n",
       "SECOND_TERM_ATTEMPT_HRS     206\n",
       "SECOND_TERM_EARNED_HRS      209\n",
       "COST_OF_ATTEND                0\n",
       "EST_FAM_CONTRIBUTION          0\n",
       "absentee_hrs_f                0\n",
       "absentee_hrs_s              209\n",
       "prnts_edn_cd                407\n",
       "entrance_score_ge1340         0\n",
       "fin_asst_req                  0\n",
       "intl_flag                     0\n",
       "top5_subj                     0\n",
       "ret_2nd_yr                    0\n",
       "gend_flag                     0\n",
       "grd_grp_Good                  0\n",
       "grd_grp_Poor                  0\n",
       "age_grp_age_ge20              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_data1 = incl_dummies.drop(drop_cols,axis=1)\n",
    "\n",
    "std_data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STDNT_TEST_ENTRANCE_COMB    0\n",
       "DISTANCE_FROM_HOME          0\n",
       "HIGH_SCHL_GPA               0\n",
       "FIRST_TERM_ATTEMPT_HRS      0\n",
       "FIRST_TERM_EARNED_HRS       0\n",
       "SECOND_TERM_ATTEMPT_HRS     0\n",
       "SECOND_TERM_EARNED_HRS      0\n",
       "COST_OF_ATTEND              0\n",
       "EST_FAM_CONTRIBUTION        0\n",
       "absentee_hrs_f              0\n",
       "absentee_hrs_s              0\n",
       "prnts_edn_cd                0\n",
       "entrance_score_ge1340       0\n",
       "fin_asst_req                0\n",
       "intl_flag                   0\n",
       "top5_subj                   0\n",
       "ret_2nd_yr                  0\n",
       "gend_flag                   0\n",
       "grd_grp_Good                0\n",
       "grd_grp_Poor                0\n",
       "age_grp_age_ge20            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observed missing values in absentee_hrs_s prnts_edn_cd and impute them with 0\n",
    "\n",
    "std_data1.fillna(0, inplace=True)\n",
    "\n",
    "std_data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile report preparation for EDA\n",
    "\n",
    "#prof_rep = pd_prf.ProfileReport(std_data1)\n",
    "#prof_rep.to_file('./profile_report.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8327731092436975"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest model building\n",
    "X = std_data1.drop(['ret_2nd_yr'], axis=1)\n",
    "Y = std_data1['ret_2nd_yr']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.30,random_state=200)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_mdl = RandomForestClassifier(n_estimators=173,oob_score=True,n_jobs=-1,random_state=200)\n",
    "\n",
    "rf_mdl.fit(X_train,Y_train)\n",
    "\n",
    "rf_mdl.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=173,\n",
       "                       n_jobs=-1, oob_score=True, random_state=200, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_mdl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('STDNT_TEST_ENTRANCE_COMB', 0.09300186814184833)\n",
      "('DISTANCE_FROM_HOME', 0.06393985378314425)\n",
      "('HIGH_SCHL_GPA', 0.12233065930682929)\n",
      "('FIRST_TERM_ATTEMPT_HRS', 0.04974533837023983)\n",
      "('FIRST_TERM_EARNED_HRS', 0.062420330022363746)\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.14769593917165208)\n",
      "('SECOND_TERM_EARNED_HRS', 0.13742693445436213)\n",
      "('COST_OF_ATTEND', 0.060432522618558165)\n",
      "('EST_FAM_CONTRIBUTION', 0.05407751854226362)\n",
      "('absentee_hrs_f', 0.03621489997428415)\n",
      "('absentee_hrs_s', 0.03568767927989496)\n",
      "('prnts_edn_cd', 0.04025831434227101)\n",
      "('entrance_score_ge1340', 0.0019574029914880024)\n",
      "('fin_asst_req', 0.014020774659555146)\n",
      "('intl_flag', 0.00314428454295554)\n",
      "('top5_subj', 0.02145038653278539)\n",
      "('gend_flag', 0.020420058815347922)\n",
      "('grd_grp_Good', 0.025721636879830964)\n",
      "('grd_grp_Poor', 0.006365514765819152)\n",
      "('age_grp_age_ge20', 0.003688082804506233)\n"
     ]
    }
   ],
   "source": [
    "cols = X_train.columns\n",
    "for feature  in zip(cols, rf_mdl.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'entropy', 'max_depth': 4}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "reg = DecisionTreeClassifier()\n",
    "tree_para = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,20,30,40,50,60,70,80,90,100,200,300]}\n",
    "reg_cv = GridSearchCV(reg,tree_para,cv=5)\n",
    "reg_cv.fit(X_train,Y_train)\n",
    "print(reg_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(criterion = 'gini', max_depth=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[790,  11],\n",
       "       [166,  53]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "dt.fit(X_train,Y_train)\n",
    "y_pred  = dt.predict(X_test)\n",
    "species = np.array(Y_test)\n",
    "predictions = np.array(y_pred)\n",
    "confusion_matrix(species,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=100\n",
      "For OOB score is 0.8352941176470589\n",
      "****************************\n",
      "For n_estimators=200\n",
      "For OOB score is 0.8323529411764706\n",
      "****************************\n",
      "For n_estimators=300\n",
      "For OOB score is 0.83109243697479\n",
      "****************************\n",
      "For n_estimators=400\n",
      "For OOB score is 0.8285714285714286\n",
      "****************************\n",
      "For n_estimators=500\n",
      "For OOB score is 0.8285714285714286\n",
      "****************************\n",
      "For n_estimators=600\n",
      "For OOB score is 0.8294117647058824\n",
      "****************************\n",
      "For n_estimators=700\n",
      "For OOB score is 0.8294117647058824\n",
      "****************************\n",
      "For n_estimators=800\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=900\n",
      "For OOB score is 0.8302521008403362\n",
      "****************************\n",
      "For n_estimators=1000\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=1100\n",
      "For OOB score is 0.8319327731092437\n",
      "****************************\n",
      "For n_estimators=1200\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=1300\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=1400\n",
      "For OOB score is 0.83109243697479\n",
      "****************************\n",
      "For n_estimators=1500\n",
      "For OOB score is 0.8315126050420169\n",
      "****************************\n",
      "For n_estimators=1600\n",
      "For OOB score is 0.83109243697479\n",
      "****************************\n",
      "For n_estimators=1700\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=1800\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=1900\n",
      "For OOB score is 0.8298319327731093\n",
      "****************************\n",
      "For n_estimators=2000\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=2100\n",
      "For OOB score is 0.8302521008403362\n",
      "****************************\n",
      "For n_estimators=2200\n",
      "For OOB score is 0.8298319327731093\n",
      "****************************\n",
      "For n_estimators=2300\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=2400\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=2500\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=2600\n",
      "For OOB score is 0.83109243697479\n",
      "****************************\n",
      "For n_estimators=2700\n",
      "For OOB score is 0.8302521008403362\n",
      "****************************\n",
      "For n_estimators=2800\n",
      "For OOB score is 0.8302521008403362\n",
      "****************************\n",
      "For n_estimators=2900\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=3000\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=3100\n",
      "For OOB score is 0.8302521008403362\n",
      "****************************\n",
      "For n_estimators=3200\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=3300\n",
      "For OOB score is 0.8294117647058824\n",
      "****************************\n",
      "For n_estimators=3400\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=3500\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=3600\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=3700\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=3800\n",
      "For OOB score is 0.8302521008403362\n",
      "****************************\n",
      "For n_estimators=3900\n",
      "For OOB score is 0.8302521008403362\n",
      "****************************\n",
      "For n_estimators=4000\n",
      "For OOB score is 0.8306722689075631\n",
      "****************************\n",
      "For n_estimators=4100\n",
      "For OOB score is 0.8302521008403362\n",
      "****************************\n",
      "For n_estimators=4200\n",
      "For OOB score is 0.83109243697479\n",
      "****************************\n",
      "For n_estimators=4300\n",
      "For OOB score is 0.83109243697479\n",
      "****************************\n",
      "For n_estimators=4400\n",
      "For OOB score is 0.8319327731092437\n",
      "****************************\n",
      "For n_estimators=4500\n",
      "For OOB score is 0.8315126050420169\n",
      "****************************\n",
      "For n_estimators=4600\n",
      "For OOB score is 0.8319327731092437\n",
      "****************************\n",
      "For n_estimators=4700\n",
      "For OOB score is 0.8319327731092437\n",
      "****************************\n",
      "For n_estimators=4800\n",
      "For OOB score is 0.8323529411764706\n",
      "****************************\n",
      "For n_estimators=4900\n",
      "For OOB score is 0.8319327731092437\n",
      "****************************\n",
      "For n_estimators=5000\n",
      "For OOB score is 0.8315126050420169\n",
      "****************************\n",
      "For n_estimators=5100\n",
      "For OOB score is 0.8315126050420169\n",
      "****************************\n",
      "For n_estimators=5200\n",
      "For OOB score is 0.83109243697479\n",
      "****************************\n",
      "For n_estimators=5300\n",
      "For OOB score is 0.83109243697479\n",
      "****************************\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-cb999266502e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mclf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moob_score\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0moob\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moob_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'For n_estimators='\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    328\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 330\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    331\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1015\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1017\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1018\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    907\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mready\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\multiprocessing\\pool.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 648\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    649\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    550\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 552\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    553\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for estimator in range(10000,11000,100):\n",
    "    clf=RandomForestClassifier(n_estimators=estimator,oob_score=True,n_jobs=-1,random_state=200)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    oob=clf.oob_score_\n",
    "    print('For n_estimators='+str(estimator))\n",
    "    print('For OOB score is '+str(oob))\n",
    "    print('****************************')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8127450980392157\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03926091, 0.03869862, 0.0401    , 0.03444132, 0.03591722,\n",
       "       0.15674289, 0.06141247, 0.03700826, 0.03734697, 0.03568575,\n",
       "       0.04413321, 0.03505912, 0.        , 0.05291399, 0.02953899,\n",
       "       0.03449575, 0.04788096, 0.13988416, 0.0669358 , 0.03254364],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgclf = XGBClassifier()\n",
    "parameters ={\n",
    "    \"learning_rate\" : [0.05,0.10,0.15,0.20,0.25,0.30,0.35,0.40,0.45,0.50],\n",
    "    \"gamma\":[0,0.1,0.2,0.3,0.4,0.5,0.7,0.8,0.9,1.0]\n",
    "    }\n",
    "\n",
    "grid=GridSearchCV(xgclf,parameters,scoring=\"accuracy\",cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "             estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                     colsample_bylevel=None,\n",
       "                                     colsample_bynode=None,\n",
       "                                     colsample_bytree=None, gamma=None,\n",
       "                                     gpu_id=None, importance_type='gain',\n",
       "                                     interaction_constraints=None,\n",
       "                                     learning_rate=None, max_delta_step=None,\n",
       "                                     max_depth=None, min_child_weight=None,\n",
       "                                     missing=nan, monotone_constrai...\n",
       "                                     random_state=None, reg_alpha=None,\n",
       "                                     reg_lambda=None, scale_pos_weight=None,\n",
       "                                     subsample=None, tree_method=None,\n",
       "                                     validate_parameters=False,\n",
       "                                     verbosity=None),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.7, 0.8, 0.9,\n",
       "                                   1.0],\n",
       "                         'learning_rate': [0.05, 0.1, 0.15, 0.2, 0.25, 0.3,\n",
       "                                           0.35, 0.4, 0.45, 0.5]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=0)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8225490196078431\n"
     ]
    }
   ],
   "source": [
    "y_pred=grid.predict(X_test)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0, 'learning_rate': 0.05}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8225490196078431\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(gamma=0,learning_rate=0.05)\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('STDNT_TEST_ENTRANCE_COMB', 0.031458613)\n",
      "('DISTANCE_FROM_HOME', 0.035638466)\n",
      "('HIGH_SCHL_GPA', 0.030573182)\n",
      "('FIRST_TERM_ATTEMPT_HRS', 0.030051041)\n",
      "('FIRST_TERM_EARNED_HRS', 0.02825461)\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.2427785)\n",
      "('SECOND_TERM_EARNED_HRS', 0.08219919)\n",
      "('COST_OF_ATTEND', 0.028917806)\n",
      "('EST_FAM_CONTRIBUTION', 0.030890454)\n",
      "('absentee_hrs_f', 0.028970718)\n",
      "('absentee_hrs_s', 0.035716925)\n",
      "('prnts_edn_cd', 0.021714784)\n",
      "('entrance_score_ge1340', 0.0)\n",
      "('fin_asst_req', 0.046330184)\n",
      "('intl_flag', 0.042636916)\n",
      "('top5_subj', 0.021334548)\n",
      "('gend_flag', 0.0319907)\n",
      "('grd_grp_Good', 0.14222734)\n",
      "('grd_grp_Poor', 0.045995045)\n",
      "('age_grp_age_ge20', 0.042320922)\n"
     ]
    }
   ],
   "source": [
    "for feature  in zip(cols, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['entrance_score_ge1340'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-fd10caf63847>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entrance_score_ge1340'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'entrance_score_ge1340'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4115\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4116\u001b[0m             \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4117\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4118\u001b[0m         )\n\u001b[0;32m   4119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3912\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3913\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3914\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3915\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3916\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3944\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3945\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3946\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3947\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3948\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5338\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5340\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} not found in axis\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5341\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5342\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['entrance_score_ge1340'] not found in axis\""
     ]
    }
   ],
   "source": [
    "X_train=X_train.drop(['entrance_score_ge1340'], axis=1)\n",
    "X_test=X_test.drop(['entrance_score_ge1340'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8225490196078431\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(gamma=0,learning_rate=0.05)\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('STDNT_TEST_ENTRANCE_COMB', 0.031458613)\n",
      "('DISTANCE_FROM_HOME', 0.035638466)\n",
      "('HIGH_SCHL_GPA', 0.030573182)\n",
      "('FIRST_TERM_ATTEMPT_HRS', 0.030051041)\n",
      "('FIRST_TERM_EARNED_HRS', 0.02825461)\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.2427785)\n",
      "('SECOND_TERM_EARNED_HRS', 0.08219919)\n",
      "('COST_OF_ATTEND', 0.028917806)\n",
      "('EST_FAM_CONTRIBUTION', 0.030890454)\n",
      "('absentee_hrs_f', 0.028970718)\n",
      "('absentee_hrs_s', 0.035716925)\n",
      "('prnts_edn_cd', 0.021714784)\n",
      "('fin_asst_req', 0.046330184)\n",
      "('intl_flag', 0.042636916)\n",
      "('top5_subj', 0.021334548)\n",
      "('gend_flag', 0.0319907)\n",
      "('grd_grp_Good', 0.14222734)\n",
      "('grd_grp_Poor', 0.045995045)\n",
      "('age_grp_age_ge20', 0.042320922)\n"
     ]
    }
   ],
   "source": [
    "ncols_new=X_train.columns\n",
    "for feature  in zip(ncols_new, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['STDNT_TEST_ENTRANCE_COMB', 'DISTANCE_FROM_HOME', 'HIGH_SCHL_GPA',\n",
       "       'FIRST_TERM_ATTEMPT_HRS', 'FIRST_TERM_EARNED_HRS',\n",
       "       'SECOND_TERM_ATTEMPT_HRS', 'SECOND_TERM_EARNED_HRS', 'COST_OF_ATTEND',\n",
       "       'EST_FAM_CONTRIBUTION', 'absentee_hrs_f', 'absentee_hrs_s',\n",
       "       'prnts_edn_cd', 'fin_asst_req', 'intl_flag', 'top5_subj', 'gend_flag',\n",
       "       'grd_grp_Good', 'grd_grp_Poor', 'age_grp_age_ge20'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8215686274509804\n",
      "('STDNT_TEST_ENTRANCE_COMB', 0.030895667)\n",
      "('DISTANCE_FROM_HOME', 0.033155464)\n",
      "('HIGH_SCHL_GPA', 0.029872814)\n",
      "('FIRST_TERM_ATTEMPT_HRS', 0.029025385)\n",
      "('FIRST_TERM_EARNED_HRS', 0.03293979)\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.24521056)\n",
      "('SECOND_TERM_EARNED_HRS', 0.08497068)\n",
      "('COST_OF_ATTEND', 0.028446736)\n",
      "('EST_FAM_CONTRIBUTION', 0.032395583)\n",
      "('absentee_hrs_f', 0.027915085)\n",
      "('absentee_hrs_s', 0.037197404)\n",
      "('fin_asst_req', 0.04767565)\n",
      "('intl_flag', 0.046892338)\n",
      "('top5_subj', 0.023720425)\n",
      "('gend_flag', 0.033570297)\n",
      "('grd_grp_Good', 0.14996478)\n",
      "('grd_grp_Poor', 0.04418813)\n",
      "('age_grp_age_ge20', 0.041963246)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.drop(['prnts_edn_cd'], axis=1)\n",
    "X_test=X_test.drop(['prnts_edn_cd'], axis=1)\n",
    "model = XGBClassifier(gamma=0,learning_rate=0.05)\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test,predictions))\n",
    "ncols_new=X_train.columns\n",
    "for feature  in zip(ncols_new, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8205882352941176\n",
      "('STDNT_TEST_ENTRANCE_COMB', 0.03345042)\n",
      "('DISTANCE_FROM_HOME', 0.03463281)\n",
      "('HIGH_SCHL_GPA', 0.03158429)\n",
      "('FIRST_TERM_ATTEMPT_HRS', 0.028213812)\n",
      "('FIRST_TERM_EARNED_HRS', 0.03489321)\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.25856093)\n",
      "('SECOND_TERM_EARNED_HRS', 0.0883871)\n",
      "('COST_OF_ATTEND', 0.029771179)\n",
      "('EST_FAM_CONTRIBUTION', 0.03238875)\n",
      "('absentee_hrs_f', 0.030469285)\n",
      "('absentee_hrs_s', 0.038607452)\n",
      "('fin_asst_req', 0.04533661)\n",
      "('intl_flag', 0.04497674)\n",
      "('top5_subj', 0.025020149)\n",
      "('gend_flag', 0.035316568)\n",
      "('grd_grp_Good', 0.15503027)\n",
      "('grd_grp_Poor', 0.05336048)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.drop(['age_grp_age_ge20'], axis=1)\n",
    "X_test=X_test.drop(['age_grp_age_ge20'], axis=1)\n",
    "model = XGBClassifier(gamma=0,learning_rate=0.05)\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test,predictions))\n",
    "ncols_new=X_train.columns\n",
    "for feature  in zip(ncols_new, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8235294117647058\n",
      "('STDNT_TEST_ENTRANCE_COMB', 0.035285436)\n",
      "('DISTANCE_FROM_HOME', 0.038179692)\n",
      "('HIGH_SCHL_GPA', 0.03715251)\n",
      "('FIRST_TERM_ATTEMPT_HRS', 0.03346668)\n",
      "('FIRST_TERM_EARNED_HRS', 0.036612418)\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.2809446)\n",
      "('SECOND_TERM_EARNED_HRS', 0.08984954)\n",
      "('EST_FAM_CONTRIBUTION', 0.03209525)\n",
      "('absentee_hrs_f', 0.031603023)\n",
      "('absentee_hrs_s', 0.040684458)\n",
      "('fin_asst_req', 0.031128932)\n",
      "('intl_flag', 0.047752287)\n",
      "('top5_subj', 0.022831712)\n",
      "('gend_flag', 0.03708196)\n",
      "('grd_grp_Good', 0.15411924)\n",
      "('grd_grp_Poor', 0.051212236)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.drop(['COST_OF_ATTEND'], axis=1)\n",
    "X_test=X_test.drop(['COST_OF_ATTEND'], axis=1)\n",
    "model = XGBClassifier(gamma=0,learning_rate=0.05)\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test,predictions))\n",
    "ncols_new=X_train.columns\n",
    "for feature  in zip(ncols_new, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8225490196078431\n",
      "('STDNT_TEST_ENTRANCE_COMB', 0.036785048)\n",
      "('DISTANCE_FROM_HOME', 0.038552377)\n",
      "('HIGH_SCHL_GPA', 0.034690812)\n",
      "('FIRST_TERM_ATTEMPT_HRS', 0.030609578)\n",
      "('FIRST_TERM_EARNED_HRS', 0.037123065)\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.2771895)\n",
      "('SECOND_TERM_EARNED_HRS', 0.09560184)\n",
      "('EST_FAM_CONTRIBUTION', 0.032785594)\n",
      "('absentee_hrs_f', 0.036265418)\n",
      "('absentee_hrs_s', 0.043401632)\n",
      "('fin_asst_req', 0.0360129)\n",
      "('intl_flag', 0.04709686)\n",
      "('gend_flag', 0.041651323)\n",
      "('grd_grp_Good', 0.16108976)\n",
      "('grd_grp_Poor', 0.05114428)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.drop(['top5_subj'], axis=1)\n",
    "X_test=X_test.drop(['top5_subj'], axis=1)\n",
    "model = XGBClassifier(gamma=0,learning_rate=0.05)\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test,predictions))\n",
    "ncols_new=X_train.columns\n",
    "for feature  in zip(ncols_new, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8225490196078431\n",
      "('STDNT_TEST_ENTRANCE_COMB', 0.038856953)\n",
      "('DISTANCE_FROM_HOME', 0.040423937)\n",
      "('HIGH_SCHL_GPA', 0.037813634)\n",
      "('FIRST_TERM_ATTEMPT_HRS', 0.03155206)\n",
      "('FIRST_TERM_EARNED_HRS', 0.038595416)\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.2730426)\n",
      "('SECOND_TERM_EARNED_HRS', 0.09801451)\n",
      "('EST_FAM_CONTRIBUTION', 0.034966655)\n",
      "('absentee_hrs_f', 0.035159286)\n",
      "('absentee_hrs_s', 0.04243262)\n",
      "('intl_flag', 0.055705346)\n",
      "('gend_flag', 0.038195945)\n",
      "('grd_grp_Good', 0.17350748)\n",
      "('grd_grp_Poor', 0.061733503)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.drop(['fin_asst_req'], axis=1)\n",
    "X_test=X_test.drop(['fin_asst_req'], axis=1)\n",
    "model = XGBClassifier(gamma=0,learning_rate=0.05)\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test,predictions))\n",
    "ncols_new=X_train.columns\n",
    "for feature  in zip(ncols_new, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8235294117647058\n",
      "('STDNT_TEST_ENTRANCE_COMB', 0.04039194)\n",
      "('DISTANCE_FROM_HOME', 0.036806524)\n",
      "('HIGH_SCHL_GPA', 0.03721357)\n",
      "('FIRST_TERM_ATTEMPT_HRS', 0.033709858)\n",
      "('FIRST_TERM_EARNED_HRS', 0.034705896)\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.33068427)\n",
      "('SECOND_TERM_EARNED_HRS', 0.06793932)\n",
      "('EST_FAM_CONTRIBUTION', 0.03455556)\n",
      "('absentee_hrs_f', 0.028069144)\n",
      "('absentee_hrs_s', 0.038779296)\n",
      "('intl_flag', 0.047119156)\n",
      "('grd_grp_Good', 0.2050092)\n",
      "('grd_grp_Poor', 0.06501631)\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.drop(['gend_flag'], axis=1)\n",
    "X_test=X_test.drop(['gend_flag'], axis=1)\n",
    "model = XGBClassifier(gamma=0,learning_rate=0.05)\n",
    "model.fit(X_train,Y_train)\n",
    "y_pred=model.predict(X_test)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test,predictions))\n",
    "ncols_new=X_train.columns\n",
    "for feature  in zip(ncols_new, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=10000\n",
      "For OOB score is 0.8281512605042017\n",
      "****************************\n",
      "For n_estimators=10100\n",
      "For OOB score is 0.8281512605042017\n",
      "****************************\n",
      "For n_estimators=10200\n",
      "For OOB score is 0.8281512605042017\n",
      "****************************\n",
      "For n_estimators=10300\n",
      "For OOB score is 0.8281512605042017\n",
      "****************************\n",
      "For n_estimators=10400\n",
      "For OOB score is 0.8281512605042017\n",
      "****************************\n",
      "For n_estimators=10500\n",
      "For OOB score is 0.8281512605042017\n",
      "****************************\n",
      "For n_estimators=10600\n",
      "For OOB score is 0.8281512605042017\n",
      "****************************\n",
      "For n_estimators=10700\n",
      "For OOB score is 0.8277310924369747\n",
      "****************************\n",
      "For n_estimators=10800\n",
      "For OOB score is 0.8277310924369747\n",
      "****************************\n",
      "For n_estimators=10900\n",
      "For OOB score is 0.8277310924369747\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "for estimator in range(10000,11000,100):\n",
    "    clf=RandomForestClassifier(n_estimators=estimator,oob_score=True,n_jobs=-1,random_state=200)\n",
    "    clf.fit(X_train,Y_train)\n",
    "    oob=clf.oob_score_\n",
    "    print('For n_estimators='+str(estimator))\n",
    "    print('For OOB score is '+str(oob))\n",
    "    print('****************************')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8205882352941176\n",
      "('STDNT_TEST_ENTRANCE_COMB', 0.04172749)\n",
      "('DISTANCE_FROM_HOME', 0.042000256)\n",
      "('HIGH_SCHL_GPA', 0.039905056)\n",
      "('FIRST_TERM_ATTEMPT_HRS', 0.035699066)\n",
      "('FIRST_TERM_EARNED_HRS', 0.038488045)\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.33010423)\n",
      "('SECOND_TERM_EARNED_HRS', 0.077848)\n",
      "('EST_FAM_CONTRIBUTION', 0.040034752)\n",
      "('absentee_hrs_s', 0.044091243)\n",
      "('intl_flag', 0.052837152)\n",
      "('grd_grp_Good', 0.19071129)\n",
      "('grd_grp_Poor', 0.06655339)\n"
     ]
    }
   ],
   "source": [
    "X_train_new=X_train.drop(['absentee_hrs_f'], axis=1)\n",
    "X_test_new=X_test.drop(['absentee_hrs_f'], axis=1)\n",
    "model = XGBClassifier(gamma=0,learning_rate=0.05)\n",
    "model.fit(X_train_new,Y_train)\n",
    "y_pred=model.predict(X_test_new)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test,predictions))\n",
    "ncols_new=X_train_new.columns\n",
    "for feature  in zip(ncols_new, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8205882352941176\n",
      "('HIGH_SCHL_GPA', 0.047219235)\n",
      "('FIRST_TERM_ATTEMPT_HRS', 0.038052246)\n",
      "('FIRST_TERM_EARNED_HRS', 0.045758158)\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.37348396)\n",
      "('SECOND_TERM_EARNED_HRS', 0.103096254)\n",
      "('EST_FAM_CONTRIBUTION', 0.048897576)\n",
      "('absentee_hrs_f', 0.045586586)\n",
      "('intl_flag', 0.058613952)\n",
      "('grd_grp_Good', 0.17962703)\n",
      "('grd_grp_Poor', 0.05966505)\n"
     ]
    }
   ],
   "source": [
    "X_train_final=X_train.drop(['STDNT_TEST_ENTRANCE_COMB','DISTANCE_FROM_HOME','absentee_hrs_s'], axis=1)\n",
    "X_test_final=X_test.drop(['STDNT_TEST_ENTRANCE_COMB','DISTANCE_FROM_HOME','absentee_hrs_s'], axis=1)\n",
    "model = XGBClassifier(gamma=0,learning_rate=0.05)\n",
    "model.fit(X_train_final,Y_train)\n",
    "y_pred=model.predict(X_test_final)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test,predictions))\n",
    "ncols_new=X_test_final.columns\n",
    "for feature  in zip(ncols_new, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final= std_data1[['SECOND_TERM_ATTEMPT_HRS','SECOND_TERM_EARNED_HRS','grd_grp_Good','grd_grp_Poor']]\n",
    "Y_final = std_data1['ret_2nd_yr']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train_final,X_test_final,Y_train_final,Y_test_final = train_test_split(X_final,Y_final,test_size = 0.30,random_state=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245098039215686\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.41186368)\n",
      "('SECOND_TERM_EARNED_HRS', 0.12041624)\n",
      "('grd_grp_Good', 0.40936506)\n",
      "('grd_grp_Poor', 0.058355026)\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(gamma=0,learning_rate=0.05)\n",
    "model.fit(X_train_final,Y_train_final)\n",
    "y_pred=model.predict(X_test_final)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test_final,predictions))\n",
    "ncols_new=X_test_final.columns\n",
    "for feature  in zip(ncols_new, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8254901960784313\n",
      "('SECOND_TERM_ATTEMPT_HRS', 0.55469674)\n",
      "('grd_grp_Good', 0.4453033)\n"
     ]
    }
   ],
   "source": [
    "X_train_final=X_train_final[['SECOND_TERM_ATTEMPT_HRS','grd_grp_Good']]\n",
    "X_test_final=X_test_final[['SECOND_TERM_ATTEMPT_HRS','grd_grp_Good']]\n",
    "model = XGBClassifier(gamma=0,learning_rate=0.05)\n",
    "model.fit(X_train_final,Y_train_final)\n",
    "y_pred=model.predict(X_test_final)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test_final,predictions))\n",
    "ncols_new=X_test_final.columns\n",
    "for feature  in zip(ncols_new, model.feature_importances_):\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8254901960784313\n"
     ]
    }
   ],
   "source": [
    "grid=GridSearchCV(xgclf,parameters,scoring=\"accuracy\",cv=5)\n",
    "grid.fit(X_train_final,Y_train_final)\n",
    "y_pred=grid.predict(X_test_final)\n",
    "predictions=[round(value) for value in y_pred]\n",
    "print(accuracy_score(Y_test_final,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'gamma': 0.2, 'learning_rate': 0.35}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster=None, colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0.2, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints=None,\n",
       "              learning_rate=0.35, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints=None,\n",
       "              n_estimators=100, n_jobs=0, num_parallel_tree=1,\n",
       "              objective='binary:logistic', random_state=0, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=1, subsample=1, tree_method=None,\n",
       "              validate_parameters=False, verbosity=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_estimators=100\n",
      "For OOB score is 0.834873949579832\n",
      "****************************\n",
      "For n_estimators=200\n",
      "For OOB score is 0.8365546218487395\n",
      "****************************\n",
      "For n_estimators=300\n",
      "For OOB score is 0.8352941176470589\n",
      "****************************\n",
      "For n_estimators=400\n",
      "For OOB score is 0.8357142857142857\n",
      "****************************\n",
      "For n_estimators=500\n",
      "For OOB score is 0.834873949579832\n",
      "****************************\n",
      "For n_estimators=600\n",
      "For OOB score is 0.8340336134453782\n",
      "****************************\n",
      "For n_estimators=700\n",
      "For OOB score is 0.8340336134453782\n",
      "****************************\n",
      "For n_estimators=800\n",
      "For OOB score is 0.8340336134453782\n",
      "****************************\n",
      "For n_estimators=900\n",
      "For OOB score is 0.8344537815126051\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "for estimator in range(100,1000,100):\n",
    "    clf=RandomForestClassifier(n_estimators=estimator,oob_score=True,n_jobs=-1,random_state=200)\n",
    "    clf.fit(X_train_final,Y_train_final)\n",
    "    oob=clf.oob_score_\n",
    "    print('For n_estimators='+str(estimator))\n",
    "    print('For OOB score is '+str(oob))\n",
    "    print('****************************')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8245098039215686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_final,Y_train_final)\n",
    "y_pred_logreg=logreg.predict(X_test_final)\n",
    "print(logreg.score(X_test_final,Y_test_final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[788  13]\n",
      " [166  53]]\n"
     ]
    }
   ],
   "source": [
    "confusion_matrix_logreg=confusion_matrix(Y_test_final,y_pred_logreg)\n",
    "print(confusion_matrix_logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For OOB score is 0.8365546218487395\n",
      "****************************\n"
     ]
    }
   ],
   "source": [
    "clf=RandomForestClassifier(n_estimators=200,oob_score=True,n_jobs=-1,random_state=200)\n",
    "clf.fit(X_train_final,Y_train_final)\n",
    "oob=clf.oob_score_\n",
    "print('For OOB score is '+str(oob))\n",
    "print('****************************')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84786848, 0.15213152])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
